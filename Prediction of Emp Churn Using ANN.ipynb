{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3349f13-b197-404c-98fa-8de86d9f7a15",
   "metadata": {},
   "source": [
    "# ğŸ”§ Preprocessing Steps\n",
    "ğŸ§¹ Data Cleaning:\n",
    "- Handled missing values and checked data consistency before further processing.\n",
    "\n",
    "ğŸ§¬ Categorical Encoding:\n",
    "- Transformed categorical variables into numeric using Label Encoding and One-Hot Encoding depending on the nature of the feature.\n",
    "\n",
    "ğŸ“Š Feature Separation:\n",
    "- Identified and separated categorical and numerical features to apply appropriate transformations.\n",
    "\n",
    "ğŸ“ Feature Scaling:\n",
    "- Applied StandardScaler to normalize numerical features for faster and more stable model training.\n",
    "\n",
    "ğŸ¯ Target Preparation:\n",
    "- Converted the target variable into binary format suitable for binary classification with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b9d53b-294f-4d12-a8a4-1ab285bfc106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Nadam\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc6e001-9afd-4a6b-98cb-8616e535b47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2018</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2012</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0     Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1     Bachelors         2013       Pune            1   28  Female          No   \n",
       "2     Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3       Masters         2016  Bangalore            3   27    Male          No   \n",
       "4       Masters         2017       Pune            3   24    Male         Yes   \n",
       "...         ...          ...        ...          ...  ...     ...         ...   \n",
       "4648  Bachelors         2013  Bangalore            3   26  Female          No   \n",
       "4649    Masters         2013       Pune            2   37    Male          No   \n",
       "4650    Masters         2018  New Delhi            3   27    Male          No   \n",
       "4651  Bachelors         2012  Bangalore            3   30    Male         Yes   \n",
       "4652  Bachelors         2015  Bangalore            3   33    Male         Yes   \n",
       "\n",
       "      ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                             0           0  \n",
       "1                             3           1  \n",
       "2                             2           0  \n",
       "3                             5           1  \n",
       "4                             2           1  \n",
       "...                         ...         ...  \n",
       "4648                          4           0  \n",
       "4649                          2           1  \n",
       "4650                          5           1  \n",
       "4651                          2           0  \n",
       "4652                          4           0  \n",
       "\n",
       "[4653 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'Employee.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e25844-81e4-4225-8092-3472ef937125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4653</td>\n",
       "      <td>4653.000000</td>\n",
       "      <td>4653</td>\n",
       "      <td>4653.000000</td>\n",
       "      <td>4653.000000</td>\n",
       "      <td>4653</td>\n",
       "      <td>4653</td>\n",
       "      <td>4653.000000</td>\n",
       "      <td>4653.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2778</td>\n",
       "      <td>4175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.062970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.698259</td>\n",
       "      <td>29.393295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.905652</td>\n",
       "      <td>0.343864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.863377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561435</td>\n",
       "      <td>4.826087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.558240</td>\n",
       "      <td>0.475047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Education  JoiningYear       City  PaymentTier          Age Gender  \\\n",
       "count        4653  4653.000000       4653  4653.000000  4653.000000   4653   \n",
       "unique          3          NaN          3          NaN          NaN      2   \n",
       "top     Bachelors          NaN  Bangalore          NaN          NaN   Male   \n",
       "freq         3601          NaN       2228          NaN          NaN   2778   \n",
       "mean          NaN  2015.062970        NaN     2.698259    29.393295    NaN   \n",
       "std           NaN     1.863377        NaN     0.561435     4.826087    NaN   \n",
       "min           NaN  2012.000000        NaN     1.000000    22.000000    NaN   \n",
       "25%           NaN  2013.000000        NaN     3.000000    26.000000    NaN   \n",
       "50%           NaN  2015.000000        NaN     3.000000    28.000000    NaN   \n",
       "75%           NaN  2017.000000        NaN     3.000000    32.000000    NaN   \n",
       "max           NaN  2018.000000        NaN     3.000000    41.000000    NaN   \n",
       "\n",
       "       EverBenched  ExperienceInCurrentDomain   LeaveOrNot  \n",
       "count         4653                4653.000000  4653.000000  \n",
       "unique           2                        NaN          NaN  \n",
       "top             No                        NaN          NaN  \n",
       "freq          4175                        NaN          NaN  \n",
       "mean           NaN                   2.905652     0.343864  \n",
       "std            NaN                   1.558240     0.475047  \n",
       "min            NaN                   0.000000     0.000000  \n",
       "25%            NaN                   2.000000     0.000000  \n",
       "50%            NaN                   3.000000     0.000000  \n",
       "75%            NaN                   4.000000     1.000000  \n",
       "max            NaN                   7.000000     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee76766f-6e54-4aba-814a-63a1db4e6137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  LeaveOrNot  \\\n",
       "0            2017            3   34                          0           0   \n",
       "1            2013            1   28                          3           1   \n",
       "2            2014            3   38                          2           0   \n",
       "3            2016            3   27                          5           1   \n",
       "4            2017            3   24                          2           1   \n",
       "...           ...          ...  ...                        ...         ...   \n",
       "4648         2013            3   26                          4           0   \n",
       "4649         2013            2   37                          2           1   \n",
       "4650         2018            3   27                          5           1   \n",
       "4651         2012            3   30                          2           0   \n",
       "4652         2015            3   33                          4           0   \n",
       "\n",
       "      Education_Masters  Education_PHD  City_New Delhi  City_Pune  \\\n",
       "0                     0              0               0          0   \n",
       "1                     0              0               0          1   \n",
       "2                     0              0               1          0   \n",
       "3                     1              0               0          0   \n",
       "4                     1              0               0          1   \n",
       "...                 ...            ...             ...        ...   \n",
       "4648                  0              0               0          0   \n",
       "4649                  1              0               0          1   \n",
       "4650                  1              0               1          0   \n",
       "4651                  0              0               0          0   \n",
       "4652                  0              0               0          0   \n",
       "\n",
       "      Gender_Male  EverBenched_Yes  \n",
       "0               1                0  \n",
       "1               0                0  \n",
       "2               0                0  \n",
       "3               1                0  \n",
       "4               1                1  \n",
       "...           ...              ...  \n",
       "4648            0                0  \n",
       "4649            1                0  \n",
       "4650            1                0  \n",
       "4651            1                1  \n",
       "4652            1                1  \n",
       "\n",
       "[4653 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, drop_first = True,dtype = int)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f440a0c9-d3ca-45ba-8ec9-c64a0fd56c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['JoiningYear', 'PaymentTier', 'Age', 'ExperienceInCurrentDomain',\n",
       "       'LeaveOrNot', 'Education_Masters', 'Education_PHD', 'City_New Delhi',\n",
       "       'City_Pune', 'Gender_Male', 'EverBenched_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d0d327-609e-4050-b190-6e3639eecf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data['LeaveOrNot']\n",
    "inputs = data.drop(['LeaveOrNot'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a21230-2380-4928-8355-c424883b4508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.039638</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.954645</td>\n",
       "      <td>-1.864901</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.107233</td>\n",
       "      <td>-3.025177</td>\n",
       "      <td>-0.288732</td>\n",
       "      <td>0.060554</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>1.633878</td>\n",
       "      <td>-1.217210</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.570515</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>1.783563</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>1.738277</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>-1.217210</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.502921</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>-0.495961</td>\n",
       "      <td>1.344191</td>\n",
       "      <td>2.080840</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.039638</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>-1.117650</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>2.080840</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>1.633878</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>2.955387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>-1.107233</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>-0.703191</td>\n",
       "      <td>0.702373</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>-1.217210</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>-1.107233</td>\n",
       "      <td>-1.243837</td>\n",
       "      <td>1.576334</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>2.080840</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>1.633878</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>1.576356</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>-0.495961</td>\n",
       "      <td>1.344191</td>\n",
       "      <td>2.080840</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>1.738277</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>-1.643951</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.125727</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>2.955387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>-0.033797</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.747416</td>\n",
       "      <td>0.702373</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>2.955387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      JoiningYear  PaymentTier       Age  ExperienceInCurrentDomain  \\\n",
       "0        1.039638     0.537503  0.954645                  -1.864901   \n",
       "1       -1.107233    -3.025177 -0.288732                   0.060554   \n",
       "2       -0.570515     0.537503  1.783563                  -0.581264   \n",
       "3        0.502921     0.537503 -0.495961                   1.344191   \n",
       "4        1.039638     0.537503 -1.117650                  -0.581264   \n",
       "...           ...          ...       ...                        ...   \n",
       "4648    -1.107233     0.537503 -0.703191                   0.702373   \n",
       "4649    -1.107233    -1.243837  1.576334                  -0.581264   \n",
       "4650     1.576356     0.537503 -0.495961                   1.344191   \n",
       "4651    -1.643951     0.537503  0.125727                  -0.581264   \n",
       "4652    -0.033797     0.537503  0.747416                   0.702373   \n",
       "\n",
       "      Education_Masters  Education_PHD  City_New Delhi  City_Pune  \\\n",
       "0             -0.480575      -0.200022       -0.575282  -0.612041   \n",
       "1             -0.480575      -0.200022       -0.575282   1.633878   \n",
       "2             -0.480575      -0.200022        1.738277  -0.612041   \n",
       "3              2.080840      -0.200022       -0.575282  -0.612041   \n",
       "4              2.080840      -0.200022       -0.575282   1.633878   \n",
       "...                 ...            ...             ...        ...   \n",
       "4648          -0.480575      -0.200022       -0.575282  -0.612041   \n",
       "4649           2.080840      -0.200022       -0.575282   1.633878   \n",
       "4650           2.080840      -0.200022        1.738277  -0.612041   \n",
       "4651          -0.480575      -0.200022       -0.575282  -0.612041   \n",
       "4652          -0.480575      -0.200022       -0.575282  -0.612041   \n",
       "\n",
       "      Gender_Male  EverBenched_Yes  \n",
       "0        0.821551        -0.338365  \n",
       "1       -1.217210        -0.338365  \n",
       "2       -1.217210        -0.338365  \n",
       "3        0.821551        -0.338365  \n",
       "4        0.821551         2.955387  \n",
       "...           ...              ...  \n",
       "4648    -1.217210        -0.338365  \n",
       "4649     0.821551        -0.338365  \n",
       "4650     0.821551        -0.338365  \n",
       "4651     0.821551         2.955387  \n",
       "4652     0.821551         2.955387  \n",
       "\n",
       "[4653 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(inputs)\n",
    "\n",
    "scaled = scaler.transform(inputs)\n",
    "\n",
    "inputs_scaled = pd.DataFrame(scaled, columns=inputs.columns)\n",
    "\n",
    "inputs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f298f0-3588-4ed1-8fb9-b43636246c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs_scaled, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a54797-9d10-4f9f-bae9-580f169ac2fc",
   "metadata": {},
   "source": [
    "# ğŸ—ï¸ Modeling with Artificial Neural Network (ANN)\n",
    "ğŸ§± Model Architecture:\n",
    "-Built a deep learning model using Keras Sequential API:\n",
    "\n",
    "- Input layer matching feature dimensions\n",
    "\n",
    "- Hidden layers with ReLU activation\n",
    "\n",
    "- Dropout layers to prevent overfitting\n",
    "\n",
    "- Output layer with Sigmoid activation for binary classification\n",
    "\n",
    "ğŸ›ï¸ Hyperparameter Tuning with Optuna:\n",
    "- Used Optuna to find optimal values for:\n",
    "\n",
    "- Number of hidden layers and neurons\n",
    "\n",
    "- Activation functions\n",
    "\n",
    "- Learning rate\n",
    "\n",
    "- Batch size and number of epochs\n",
    "\n",
    "ğŸ§ª Model Training & Evaluation:\n",
    "-Trained the optimized ANN using best hyperparameters. Evaluated performance using:\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- Precision, Recall, F1-Score\n",
    "\n",
    "- ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9773bee1-1f27-4620-b873-6c5b0c4cd0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66edfec2-4457-4703-8d10-21eeded61b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    # Building artificial neural network\n",
    "    model = Sequential()\n",
    "\n",
    "     # we add 2 hidden layers and 1 output layer\n",
    "    model.add(Dense(units=trial.suggest_int('units_layer1', 16, 256), activation='relu'))\n",
    "    model.add(Dense(units=trial.suggest_int('units_layer2', 16, 256), activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Suggest hyperparameters for the optimizer\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop', 'adagrad'])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    \n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'adagrad':\n",
    "        optimizer = Adagrad(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5623c2e1-a3a5-460a-9ce3-28e60f6bb4a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:35:58,149] A new study created in memory with name: no-name-643d24b9-1ce7-48b8-a9ec-5e26ed634ee0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.5093 - loss: 0.6569\n",
      "Epoch 2/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6497 - loss: 0.6305\n",
      "Epoch 3/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7020 - loss: 0.6113\n",
      "Epoch 4/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7459 - loss: 0.5921\n",
      "Epoch 5/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7558 - loss: 0.5825\n",
      "Epoch 6/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7572 - loss: 0.5673\n",
      "Epoch 7/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7681 - loss: 0.5554\n",
      "Epoch 8/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7647 - loss: 0.5592\n",
      "Epoch 9/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7818 - loss: 0.5490\n",
      "Epoch 10/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7793 - loss: 0.5398\n",
      "Epoch 11/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7777 - loss: 0.5279\n",
      "Epoch 12/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7821 - loss: 0.5318\n",
      "Epoch 13/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7943 - loss: 0.5218\n",
      "Epoch 14/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7875 - loss: 0.5272\n",
      "Epoch 15/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7836 - loss: 0.5214\n",
      "Epoch 16/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8029 - loss: 0.5043\n",
      "Epoch 17/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7909 - loss: 0.5108\n",
      "Epoch 18/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8035 - loss: 0.5030\n",
      "Epoch 19/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8004 - loss: 0.5036\n",
      "Epoch 20/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7910 - loss: 0.5109\n",
      "Epoch 21/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7873 - loss: 0.5121\n",
      "Epoch 22/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7995 - loss: 0.4919\n",
      "Epoch 23/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8102 - loss: 0.4964\n",
      "Epoch 24/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8088 - loss: 0.4932\n",
      "Epoch 25/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8030 - loss: 0.4922\n",
      "Epoch 26/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8110 - loss: 0.4951\n",
      "Epoch 27/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8071 - loss: 0.4882\n",
      "Epoch 28/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8230 - loss: 0.4748\n",
      "Epoch 29/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8191 - loss: 0.4876\n",
      "Epoch 30/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8282 - loss: 0.4670\n",
      "Epoch 31/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8096 - loss: 0.4815\n",
      "Epoch 32/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8089 - loss: 0.4874\n",
      "Epoch 33/33\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8198 - loss: 0.4855\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:36:06,962] Trial 0 finished with value: 0.8503472754200501 and parameters: {'epochs': 33, 'batch_size': 53, 'units_layer1': 250, 'units_layer2': 207, 'optimizer': 'adam', 'learning_rate': 2.1457423334836293e-05}. Best is trial 0 with value: 0.8503472754200501.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.5402 - loss: 0.7095\n",
      "Epoch 2/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5663 - loss: 0.6904\n",
      "Epoch 3/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6000 - loss: 0.6757\n",
      "Epoch 4/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6406 - loss: 0.6624\n",
      "Epoch 5/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6583 - loss: 0.6501\n",
      "Epoch 6/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6655 - loss: 0.6414\n",
      "Epoch 7/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6949 - loss: 0.6301\n",
      "Epoch 8/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7124 - loss: 0.6207\n",
      "Epoch 9/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7124 - loss: 0.6130\n",
      "Epoch 10/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7206 - loss: 0.6055\n",
      "Epoch 11/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7591 - loss: 0.5916\n",
      "Epoch 12/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7491 - loss: 0.5918\n",
      "Epoch 13/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7622 - loss: 0.5808\n",
      "Epoch 14/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7513 - loss: 0.5873\n",
      "Epoch 15/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7655 - loss: 0.5726\n",
      "Epoch 16/16\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7616 - loss: 0.5716\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:36:11,809] Trial 1 finished with value: 0.7995071753230172 and parameters: {'epochs': 16, 'batch_size': 39, 'units_layer1': 185, 'units_layer2': 42, 'optimizer': 'adam', 'learning_rate': 1.3642844418194035e-05}. Best is trial 0 with value: 0.8503472754200501.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.4647 - loss: 0.6848\n",
      "Epoch 2/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4712 - loss: 0.6828\n",
      "Epoch 3/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4727 - loss: 0.6812\n",
      "Epoch 4/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4914 - loss: 0.6761\n",
      "Epoch 5/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4913 - loss: 0.6791\n",
      "Epoch 6/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4747 - loss: 0.6754\n",
      "Epoch 7/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4883 - loss: 0.6761\n",
      "Epoch 8/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4971 - loss: 0.6700\n",
      "Epoch 9/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4990 - loss: 0.6729\n",
      "Epoch 10/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5127 - loss: 0.6701\n",
      "Epoch 11/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5104 - loss: 0.6668\n",
      "Epoch 12/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5331 - loss: 0.6666\n",
      "Epoch 13/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5305 - loss: 0.6670\n",
      "Epoch 14/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5421 - loss: 0.6621\n",
      "Epoch 15/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5288 - loss: 0.6646\n",
      "Epoch 16/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5407 - loss: 0.6618\n",
      "Epoch 17/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5440 - loss: 0.6621\n",
      "Epoch 18/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5294 - loss: 0.6627\n",
      "Epoch 19/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5442 - loss: 0.6586\n",
      "Epoch 20/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5684 - loss: 0.6564\n",
      "Epoch 21/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5557 - loss: 0.6555\n",
      "Epoch 22/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5635 - loss: 0.6550\n",
      "Epoch 23/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5497 - loss: 0.6599\n",
      "Epoch 24/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5635 - loss: 0.6546\n",
      "Epoch 25/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5504 - loss: 0.6541\n",
      "Epoch 26/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5687 - loss: 0.6502\n",
      "Epoch 27/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5626 - loss: 0.6506\n",
      "Epoch 28/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5672 - loss: 0.6510\n",
      "Epoch 29/29\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5742 - loss: 0.6486\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:36:20,038] Trial 2 finished with value: 0.593810326336755 and parameters: {'epochs': 29, 'batch_size': 29, 'units_layer1': 155, 'units_layer2': 51, 'optimizer': 'adagrad', 'learning_rate': 9.309888114192167e-05}. Best is trial 0 with value: 0.8503472754200501.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.5964 - loss: 0.6735 \n",
      "Epoch 2/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6110 - loss: 0.6641\n",
      "Epoch 3/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6518 - loss: 0.6520\n",
      "Epoch 4/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6550 - loss: 0.6458\n",
      "Epoch 5/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6625 - loss: 0.6430\n",
      "Epoch 6/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6810 - loss: 0.6293\n",
      "Epoch 7/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6955 - loss: 0.6348\n",
      "Epoch 8/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6993 - loss: 0.6240\n",
      "Epoch 9/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6956 - loss: 0.6209\n",
      "Epoch 10/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7064 - loss: 0.6153\n",
      "Epoch 11/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7101 - loss: 0.6133\n",
      "Epoch 12/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7227 - loss: 0.6099\n",
      "Epoch 13/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7120 - loss: 0.6048\n",
      "Epoch 14/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7277 - loss: 0.6043\n",
      "Epoch 15/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7308 - loss: 0.5989\n",
      "Epoch 16/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7254 - loss: 0.6044\n",
      "Epoch 17/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7257 - loss: 0.6029\n",
      "Epoch 18/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7360 - loss: 0.5876\n",
      "Epoch 19/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7450 - loss: 0.5932\n",
      "Epoch 20/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7507 - loss: 0.5854\n",
      "Epoch 21/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7296 - loss: 0.5892\n",
      "Epoch 22/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7402 - loss: 0.5882\n",
      "Epoch 23/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7517 - loss: 0.5844\n",
      "Epoch 24/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7605 - loss: 0.5808\n",
      "Epoch 25/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7436 - loss: 0.5806\n",
      "Epoch 26/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7505 - loss: 0.5782\n",
      "Epoch 27/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7425 - loss: 0.5793\n",
      "Epoch 28/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7420 - loss: 0.5756\n",
      "Epoch 29/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7383 - loss: 0.5833\n",
      "Epoch 30/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7472 - loss: 0.5720\n",
      "Epoch 31/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7375 - loss: 0.5741\n",
      "Epoch 32/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7600 - loss: 0.5712\n",
      "Epoch 33/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7476 - loss: 0.5723\n",
      "Epoch 34/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7583 - loss: 0.5704\n",
      "Epoch 35/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7495 - loss: 0.5663\n",
      "Epoch 36/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7453 - loss: 0.5703\n",
      "Epoch 37/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7502 - loss: 0.5666\n",
      "Epoch 38/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7534 - loss: 0.5648\n",
      "Epoch 39/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7686 - loss: 0.5487\n",
      "Epoch 40/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7458 - loss: 0.5679\n",
      "Epoch 41/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7634 - loss: 0.5566\n",
      "Epoch 42/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7576 - loss: 0.5581\n",
      "Epoch 43/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7676 - loss: 0.5523\n",
      "Epoch 44/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7694 - loss: 0.5565\n",
      "Epoch 45/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7657 - loss: 0.5607\n",
      "Epoch 46/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7579 - loss: 0.5573\n",
      "Epoch 47/47\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7643 - loss: 0.5553\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:36:33,090] Trial 3 finished with value: 0.801345692252694 and parameters: {'epochs': 47, 'batch_size': 30, 'units_layer1': 160, 'units_layer2': 182, 'optimizer': 'adagrad', 'learning_rate': 0.0003653078320566086}. Best is trial 0 with value: 0.8503472754200501.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.5236 - loss: 0.7209\n",
      "Epoch 2/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5230 - loss: 0.7198\n",
      "Epoch 3/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5209 - loss: 0.7191\n",
      "Epoch 4/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5207 - loss: 0.7197\n",
      "Epoch 5/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5254 - loss: 0.7181\n",
      "Epoch 6/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5350 - loss: 0.7143\n",
      "Epoch 7/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5292 - loss: 0.7155\n",
      "Epoch 8/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5270 - loss: 0.7176\n",
      "Epoch 9/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5339 - loss: 0.7153\n",
      "Epoch 10/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5382 - loss: 0.7109\n",
      "Epoch 11/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5303 - loss: 0.7143\n",
      "Epoch 12/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5419 - loss: 0.7103\n",
      "Epoch 13/13\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5473 - loss: 0.7103\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:36:37,074] Trial 4 finished with value: 0.5765052857361728 and parameters: {'epochs': 13, 'batch_size': 31, 'units_layer1': 173, 'units_layer2': 62, 'optimizer': 'adagrad', 'learning_rate': 2.3993190657276922e-05}. Best is trial 0 with value: 0.8503472754200501.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - AUC: 0.6630 - loss: 0.6117\n",
      "Epoch 2/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7576 - loss: 0.5459\n",
      "Epoch 3/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7786 - loss: 0.5097\n",
      "Epoch 4/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7959 - loss: 0.5041\n",
      "Epoch 5/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7965 - loss: 0.5006\n",
      "Epoch 6/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7959 - loss: 0.4916\n",
      "Epoch 7/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8198 - loss: 0.4710\n",
      "Epoch 8/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8260 - loss: 0.4680\n",
      "Epoch 9/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8233 - loss: 0.4679\n",
      "Epoch 10/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8318 - loss: 0.4562\n",
      "Epoch 11/11\n",
      "\u001b[1m219/219\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8290 - loss: 0.4529\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:36:42,408] Trial 5 finished with value: 0.866482814973699 and parameters: {'epochs': 11, 'batch_size': 17, 'units_layer1': 43, 'units_layer2': 172, 'optimizer': 'rmsprop', 'learning_rate': 0.0002214127368581312}. Best is trial 5 with value: 0.866482814973699.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.6266 - loss: 0.6447\n",
      "Epoch 2/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6743 - loss: 0.6364\n",
      "Epoch 3/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7178 - loss: 0.6128\n",
      "Epoch 4/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7461 - loss: 0.6043\n",
      "Epoch 5/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7379 - loss: 0.5994\n",
      "Epoch 6/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7320 - loss: 0.5953\n",
      "Epoch 7/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7596 - loss: 0.5835\n",
      "Epoch 8/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7615 - loss: 0.5794\n",
      "Epoch 9/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7525 - loss: 0.5773\n",
      "Epoch 10/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7442 - loss: 0.5730\n",
      "Epoch 11/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7614 - loss: 0.5638\n",
      "Epoch 12/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7643 - loss: 0.5551\n",
      "Epoch 13/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7663 - loss: 0.5556\n",
      "Epoch 14/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7622 - loss: 0.5557\n",
      "Epoch 15/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7765 - loss: 0.5469\n",
      "Epoch 16/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7797 - loss: 0.5380\n",
      "Epoch 17/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7837 - loss: 0.5380\n",
      "Epoch 18/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7809 - loss: 0.5350\n",
      "Epoch 19/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7768 - loss: 0.5301\n",
      "Epoch 20/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7686 - loss: 0.5380\n",
      "Epoch 21/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7759 - loss: 0.5344\n",
      "Epoch 22/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7785 - loss: 0.5382\n",
      "Epoch 23/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7758 - loss: 0.5457\n",
      "Epoch 24/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7817 - loss: 0.5308\n",
      "Epoch 25/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7909 - loss: 0.5183\n",
      "Epoch 26/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7996 - loss: 0.5143\n",
      "Epoch 27/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8056 - loss: 0.5126\n",
      "Epoch 28/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8081 - loss: 0.5051\n",
      "Epoch 29/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7939 - loss: 0.5185\n",
      "Epoch 30/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7920 - loss: 0.5157\n",
      "Epoch 31/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7886 - loss: 0.5129\n",
      "Epoch 32/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7851 - loss: 0.5212\n",
      "Epoch 33/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8002 - loss: 0.5095\n",
      "Epoch 34/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7972 - loss: 0.5040\n",
      "Epoch 35/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7917 - loss: 0.5122\n",
      "Epoch 36/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7959 - loss: 0.5097\n",
      "Epoch 37/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7937 - loss: 0.5080\n",
      "Epoch 38/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7980 - loss: 0.5057\n",
      "Epoch 39/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7970 - loss: 0.5053\n",
      "Epoch 40/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8080 - loss: 0.4983\n",
      "Epoch 41/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7942 - loss: 0.5119\n",
      "Epoch 42/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7887 - loss: 0.5180\n",
      "Epoch 43/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7856 - loss: 0.5133\n",
      "Epoch 44/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8085 - loss: 0.4927\n",
      "Epoch 45/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8156 - loss: 0.4937\n",
      "Epoch 46/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8061 - loss: 0.4948\n",
      "Epoch 47/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8063 - loss: 0.4928\n",
      "Epoch 48/48\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8059 - loss: 0.4923\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:36:55,795] Trial 6 finished with value: 0.8461340074562076 and parameters: {'epochs': 48, 'batch_size': 30, 'units_layer1': 145, 'units_layer2': 178, 'optimizer': 'adam', 'learning_rate': 1.0981722958571015e-05}. Best is trial 5 with value: 0.866482814973699.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.7129 - loss: 0.5688\n",
      "Epoch 2/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8058 - loss: 0.4925\n",
      "Epoch 3/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8169 - loss: 0.4734\n",
      "Epoch 4/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8411 - loss: 0.4348\n",
      "Epoch 5/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8446 - loss: 0.4334\n",
      "Epoch 6/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8539 - loss: 0.4180\n",
      "Epoch 7/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8502 - loss: 0.4187\n",
      "Epoch 8/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8666 - loss: 0.3973\n",
      "Epoch 9/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8691 - loss: 0.3964\n",
      "Epoch 10/10\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8626 - loss: 0.3988\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:36:59,247] Trial 7 finished with value: 0.8779939737500637 and parameters: {'epochs': 10, 'batch_size': 44, 'units_layer1': 209, 'units_layer2': 102, 'optimizer': 'rmsprop', 'learning_rate': 0.00063733429173596}. Best is trial 7 with value: 0.8779939737500637.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.6811 - loss: 0.6052 \n",
      "Epoch 2/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7869 - loss: 0.5100\n",
      "Epoch 3/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8155 - loss: 0.4752\n",
      "Epoch 4/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8226 - loss: 0.4730\n",
      "Epoch 5/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8404 - loss: 0.4442\n",
      "Epoch 6/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8362 - loss: 0.4444\n",
      "Epoch 7/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8529 - loss: 0.4270\n",
      "Epoch 8/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8395 - loss: 0.4273\n",
      "Epoch 9/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8604 - loss: 0.4058\n",
      "Epoch 10/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8626 - loss: 0.3929\n",
      "Epoch 11/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8716 - loss: 0.3917\n",
      "Epoch 12/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8698 - loss: 0.3880\n",
      "Epoch 13/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8702 - loss: 0.3881\n",
      "Epoch 14/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8760 - loss: 0.3760\n",
      "Epoch 15/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8663 - loss: 0.3836\n",
      "Epoch 16/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8884 - loss: 0.3632\n",
      "Epoch 17/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8735 - loss: 0.3763\n",
      "Epoch 18/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8834 - loss: 0.3711\n",
      "Epoch 19/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8779 - loss: 0.3727\n",
      "Epoch 20/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8868 - loss: 0.3553\n",
      "Epoch 21/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8818 - loss: 0.3698\n",
      "Epoch 22/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8884 - loss: 0.3586\n",
      "Epoch 23/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8907 - loss: 0.3469\n",
      "Epoch 24/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8879 - loss: 0.3508\n",
      "Epoch 25/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8878 - loss: 0.3529\n",
      "Epoch 26/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8796 - loss: 0.3628\n",
      "Epoch 27/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8979 - loss: 0.3345\n",
      "Epoch 28/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8925 - loss: 0.3483\n",
      "Epoch 29/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8922 - loss: 0.3511\n",
      "Epoch 30/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.9001 - loss: 0.3278\n",
      "Epoch 31/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8973 - loss: 0.3465\n",
      "Epoch 32/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8968 - loss: 0.3399\n",
      "Epoch 33/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8937 - loss: 0.3497\n",
      "Epoch 34/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8991 - loss: 0.3415\n",
      "Epoch 35/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8911 - loss: 0.3461\n",
      "Epoch 36/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8990 - loss: 0.3501\n",
      "Epoch 37/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.9066 - loss: 0.3254\n",
      "Epoch 38/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.9092 - loss: 0.3254\n",
      "Epoch 39/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8867 - loss: 0.3491\n",
      "Epoch 40/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.9021 - loss: 0.3337\n",
      "Epoch 41/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.9070 - loss: 0.3317\n",
      "Epoch 42/42\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.9053 - loss: 0.3267\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:37:10,226] Trial 8 finished with value: 0.8976226954700985 and parameters: {'epochs': 42, 'batch_size': 31, 'units_layer1': 27, 'units_layer2': 110, 'optimizer': 'rmsprop', 'learning_rate': 0.0010923807647814207}. Best is trial 8 with value: 0.8976226954700985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIcat\\AppData\\Local\\Temp\\ipykernel_14828\\312609459.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.6412 - loss: 0.6361\n",
      "Epoch 2/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7468 - loss: 0.5622\n",
      "Epoch 3/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7752 - loss: 0.5280\n",
      "Epoch 4/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7802 - loss: 0.5182\n",
      "Epoch 5/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7741 - loss: 0.5211\n",
      "Epoch 6/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7969 - loss: 0.4977\n",
      "Epoch 7/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8111 - loss: 0.4893\n",
      "Epoch 8/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8253 - loss: 0.4700\n",
      "Epoch 9/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8192 - loss: 0.4699\n",
      "Epoch 10/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8269 - loss: 0.4672\n",
      "Epoch 11/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8349 - loss: 0.4521\n",
      "Epoch 12/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.8277 - loss: 0.4609\n",
      "Epoch 13/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8391 - loss: 0.4461\n",
      "Epoch 14/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8372 - loss: 0.4535\n",
      "Epoch 15/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8426 - loss: 0.4435\n",
      "Epoch 16/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8439 - loss: 0.4375\n",
      "Epoch 17/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8577 - loss: 0.4243\n",
      "Epoch 18/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8440 - loss: 0.4373\n",
      "Epoch 19/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8433 - loss: 0.4383\n",
      "Epoch 20/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8430 - loss: 0.4390\n",
      "Epoch 21/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8473 - loss: 0.4349\n",
      "Epoch 22/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8561 - loss: 0.4136\n",
      "Epoch 23/23\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8621 - loss: 0.4159\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:37:16,598] Trial 9 finished with value: 0.8776824472703129 and parameters: {'epochs': 23, 'batch_size': 50, 'units_layer1': 249, 'units_layer2': 145, 'optimizer': 'rmsprop', 'learning_rate': 0.00013439965662162933}. Best is trial 8 with value: 0.8976226954700985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0.8976226954700985\n",
      "Best hyperparameters: {'epochs': 42, 'batch_size': 31, 'units_layer1': 27, 'units_layer2': 110, 'optimizer': 'rmsprop', 'learning_rate': 0.0010923807647814207}\n"
     ]
    }
   ],
   "source": [
    "def optimal(trial):\n",
    "    \n",
    "    # Suggest the number of epochs and batch size\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    \n",
    "    model = create_model(trial)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimal, n_trials=10)\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.value}\")\n",
    "print(f\"Best hyperparameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3255a114-9c45-4c7d-9a52-f3bae9683f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 42,\n",
       " 'batch_size': 31,\n",
       " 'units_layer1': 27,\n",
       " 'units_layer2': 110,\n",
       " 'optimizer': 'rmsprop',\n",
       " 'learning_rate': 0.0010923807647814207}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "308686a1-388d-4872-ad17-691544f53a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "\n",
    "best_model = Sequential()\n",
    "best_model.add(Dense(units=best_params['units_layer1'], activation='relu'))\n",
    "best_model.add(Dense(units=best_params['units_layer2'], activation='relu'))\n",
    "\n",
    "best_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8da31cb1-6b39-4e41-a085-636307298437",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_params['optimizer'] == 'adam':\n",
    "    best_optimizer = Adam(learning_rate=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'sgd':\n",
    "    best_optimizer = SGD(learning_rate=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'rmsprop':\n",
    "    best_optimizer = RMSprop(learning_rate=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'adagrad':\n",
    "    best_optimizer = Adagrad(learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bee6328-0137-40df-9fc1-e0749f555328",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=best_optimizer, loss='binary_crossentropy', metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda5caa1-0389-413a-8d20-d1ffed6c4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=38, batch_size=best_params['batch_size'])\n",
    "    \n",
    "    '''Predictions and probabilities for the training set'''\n",
    "    \n",
    "    y_train_prob = model.predict(X_train)\n",
    "\n",
    "    '''Predictions and probabilities for the test set'''\n",
    "    \n",
    "    y_test_prob = model.predict(X_test)\n",
    "\n",
    "    '''Calculate metrics for the training set''' \n",
    "    \n",
    "    roc_train_prob = roc_auc_score(y_train, y_train_prob)\n",
    "    gini_train_prob = roc_train_prob * 2 - 1\n",
    "    \n",
    "\n",
    "    '''Calculate metrics for the test set'''\n",
    "    \n",
    "    roc_test_prob = roc_auc_score(y_test, y_test_prob)\n",
    "    gini_test_prob = roc_test_prob * 2 - 1\n",
    "    \n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Dataset': ['Train', 'Test'],\n",
    "        'Gini': [gini_train_prob * 100, gini_test_prob * 100],\n",
    "    \n",
    "    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba78c5b5-9d59-4afa-868d-0be72877cc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - AUC: 0.6430 - loss: 0.6188 \n",
      "Epoch 2/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7988 - loss: 0.5078\n",
      "Epoch 3/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7991 - loss: 0.4913\n",
      "Epoch 4/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8333 - loss: 0.4529\n",
      "Epoch 5/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8471 - loss: 0.4322\n",
      "Epoch 6/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8579 - loss: 0.4203\n",
      "Epoch 7/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8494 - loss: 0.4307\n",
      "Epoch 8/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8608 - loss: 0.4088\n",
      "Epoch 9/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8581 - loss: 0.4114\n",
      "Epoch 10/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8541 - loss: 0.4126\n",
      "Epoch 11/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8654 - loss: 0.4005\n",
      "Epoch 12/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8656 - loss: 0.3907\n",
      "Epoch 13/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8564 - loss: 0.3983\n",
      "Epoch 14/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8701 - loss: 0.3833\n",
      "Epoch 15/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8692 - loss: 0.3834\n",
      "Epoch 16/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8837 - loss: 0.3607\n",
      "Epoch 17/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8797 - loss: 0.3765\n",
      "Epoch 18/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8794 - loss: 0.3672\n",
      "Epoch 19/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8801 - loss: 0.3606\n",
      "Epoch 20/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8845 - loss: 0.3540\n",
      "Epoch 21/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8801 - loss: 0.3628\n",
      "Epoch 22/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8737 - loss: 0.3749\n",
      "Epoch 23/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8816 - loss: 0.3688\n",
      "Epoch 24/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8840 - loss: 0.3619\n",
      "Epoch 25/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8887 - loss: 0.3534\n",
      "Epoch 26/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8932 - loss: 0.3429\n",
      "Epoch 27/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8814 - loss: 0.3596\n",
      "Epoch 28/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8770 - loss: 0.3743\n",
      "Epoch 29/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8856 - loss: 0.3606\n",
      "Epoch 30/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8892 - loss: 0.3408\n",
      "Epoch 31/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8945 - loss: 0.3420\n",
      "Epoch 32/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8936 - loss: 0.3443\n",
      "Epoch 33/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.9026 - loss: 0.3341\n",
      "Epoch 34/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8930 - loss: 0.3499\n",
      "Epoch 35/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8899 - loss: 0.3434\n",
      "Epoch 36/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8998 - loss: 0.3403\n",
      "Epoch 37/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8973 - loss: 0.3452\n",
      "Epoch 38/38\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8955 - loss: 0.3391\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>80.533266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>79.770185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset       Gini\n",
       "0   Train  80.533266\n",
       "1    Test  79.770185"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4ad70-930e-4737-b73c-52ad03a37f1b",
   "metadata": {},
   "source": [
    "# ğŸš€ Deployment \n",
    "ğŸ“¥ Input new employee data\n",
    "\n",
    "- New employee information is entered directly as a dictionary or a DataFrame.\n",
    "\n",
    "ğŸ§¼ Convert categorical columns to numeric format\n",
    "\n",
    "- Categorical variables like Education, Gender, City, and EverBenched are converted using One-Hot Encoding (get_dummies()).\n",
    "\n",
    "ğŸ§© Align columns with what the model expects\n",
    "\n",
    "- Check if any columns used during training are missing in the new data; if so, add them with default value 0.\n",
    "\n",
    "- Make sure the column order matches the training data.\n",
    "\n",
    "ğŸ“ Scale the data using the same scaler\n",
    "\n",
    "- Use the StandardScaler instance that was fit during training to transform the new data accordingly (without saving/loading from disk).\n",
    "\n",
    "ğŸ§  Make predictions using the trained ANN model\n",
    "\n",
    "- Feed the scaled data into the trained ANN model to get predictions (whether the employee will leave or not).\n",
    "\n",
    "ğŸ“‹ Add the prediction to the results\n",
    "\n",
    "- Append the prediction (e.g., a leaveornot column with values 0 or 1) to the original data to present the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b3da4e0-1612-4390-a6a5-4501aeff85d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHD</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHD</td>\n",
       "      <td>2018</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2019</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2015  Bangalore            1   25    Male          No   \n",
       "1        PHD         2016       Pune            2   30  Female         Yes   \n",
       "2    Masters         2017  New Delhi            1   28    Male          No   \n",
       "3        PHD         2018  New Delhi            3   35    Male         Yes   \n",
       "4    Masters         2019       Pune            2   32  Female          No   \n",
       "\n",
       "   ExperienceInCurrentDomain  \n",
       "0                          1  \n",
       "1                          3  \n",
       "2                          2  \n",
       "3                          4  \n",
       "4                          5  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {\n",
    "    'Education': ['Bachelors', 'PHD', 'Masters', 'PHD', 'Masters'],\n",
    "    'JoiningYear': [2015, 2016, 2017, 2018, 2019],\n",
    "    'City': ['Bangalore', 'Pune', 'New Delhi', 'New Delhi', 'Pune'],\n",
    "    'PaymentTier': [1, 2, 1, 3, 2],\n",
    "    'Age': [25, 30, 28, 35, 32],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Male', 'Female'],\n",
    "    'EverBenched': ['No', 'Yes', 'No', 'Yes', 'No'],\n",
    "    'ExperienceInCurrentDomain': [1, 3, 2, 4, 5]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(df)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "631c85d0-d67c-4b28-9338-a0a927e880a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  \\\n",
       "0         2015            1   25                          1   \n",
       "1         2016            2   30                          3   \n",
       "2         2017            1   28                          2   \n",
       "3         2018            3   35                          4   \n",
       "4         2019            2   32                          5   \n",
       "\n",
       "   Education_Masters  Education_PHD  City_New Delhi  City_Pune  Gender_Male  \\\n",
       "0                  0              0               0          0            1   \n",
       "1                  0              1               0          1            0   \n",
       "2                  1              0               1          0            1   \n",
       "3                  0              1               1          0            1   \n",
       "4                  1              0               0          1            0   \n",
       "\n",
       "   EverBenched_Yes  \n",
       "0                0  \n",
       "1                1  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.get_dummies(df1,drop_first = True,dtype = int )\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0c98123-b586-4bb0-bd6d-1f433bd3a444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.414214</td>\n",
       "      <td>-1.069045</td>\n",
       "      <td>-1.468051</td>\n",
       "      <td>-1.414214</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.069045</td>\n",
       "      <td>-0.587220</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.603567</td>\n",
       "      <td>1.468051</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.224745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.587220</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-0.816497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JoiningYear  PaymentTier       Age  ExperienceInCurrentDomain  \\\n",
       "0    -1.414214    -1.069045 -1.468051                  -1.414214   \n",
       "1    -0.707107     0.267261  0.000000                   0.000000   \n",
       "2     0.000000    -1.069045 -0.587220                  -0.707107   \n",
       "3     0.707107     1.603567  1.468051                   0.707107   \n",
       "4     1.414214     0.267261  0.587220                   1.414214   \n",
       "\n",
       "   Education_Masters  Education_PHD  City_New Delhi  City_Pune  Gender_Male  \\\n",
       "0          -0.816497      -0.816497       -0.816497  -0.816497     0.816497   \n",
       "1          -0.816497       1.224745       -0.816497   1.224745    -1.224745   \n",
       "2           1.224745      -0.816497        1.224745  -0.816497     0.816497   \n",
       "3          -0.816497       1.224745        1.224745  -0.816497     0.816497   \n",
       "4           1.224745      -0.816497       -0.816497   1.224745    -1.224745   \n",
       "\n",
       "   EverBenched_Yes  \n",
       "0        -0.816497  \n",
       "1         1.224745  \n",
       "2        -0.816497  \n",
       "3         1.224745  \n",
       "4        -0.816497  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(df1)\n",
    "\n",
    "scaled = scaler.transform(df1)\n",
    "\n",
    "df_test_scaled = pd.DataFrame(scaled, columns=df1.columns)\n",
    "\n",
    "df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63b78da6-63c5-4dfb-8baf-91d1446f7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled=df_test_scaled[['JoiningYear','PaymentTier','Age','ExperienceInCurrentDomain','Education_Masters','Education_PHD','City_New Delhi','City_Pune','Gender_Male','EverBenched_Yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b54716dd-e20e-48d5-a1e0-5ff84560f714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "      <th>leaveornot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  \\\n",
       "0         2015            1   25                          1   \n",
       "1         2016            2   30                          3   \n",
       "2         2017            1   28                          2   \n",
       "3         2018            3   35                          4   \n",
       "4         2019            2   32                          5   \n",
       "\n",
       "   Education_Masters  Education_PHD  City_New Delhi  City_Pune  Gender_Male  \\\n",
       "0                  0              0               0          0            1   \n",
       "1                  0              1               0          1            0   \n",
       "2                  1              0               1          0            1   \n",
       "3                  0              1               1          0            1   \n",
       "4                  1              0               0          1            0   \n",
       "\n",
       "   EverBenched_Yes  leaveornot  \n",
       "0                0    0.560165  \n",
       "1                1    0.934078  \n",
       "2                0    0.397841  \n",
       "3                1    0.023787  \n",
       "4                0    0.984507  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['leaveornot'] = best_model.predict(df_test_scaled)\n",
    "\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cc247-b8e6-483c-a5e8-bb2044bad448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
